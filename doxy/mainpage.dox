/***************************************************************************                                                                                     
*   Copyright 2012 - 2013 Advanced Micro Devices, Inc.                               
*                                                                                    
*   Licensed under the Apache License, Version 2.0 (the "License");   
*   you may not use this file except in compliance with the License.                 
*   You may obtain a copy of the License at                                          
*                                                                                    
*       http://www.apache.org/licenses/LICENSE-2.0                      
*                                                                                    
*   Unless required by applicable law or agreed to in writing, software              
*   distributed under the License is distributed on an "AS IS" BASIS,              
*   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.         
*   See the License for the specific language governing permissions and              
*   limitations under the License.                                                   

***************************************************************************/                                                                                     

/*!
 * \mainpage Bolt Documentation
 * \tableofcontents
 * \image html bolt.png

 * \section intro_sec Introduction
 * Bolt is a C++ template library optimized for GPUs.  
 * Bolt is designed to provide high-performance library implementations for common algorithms
 * such as scan, reduce, transform, and sort.  
 * The Bolt interface was modeled on the C++ Standard Template Library (STL). Developers familiar with 
 * STL will recognize many of the Bolt APIs and customization techniques.  
 
 * C++ templates can be used to customize the algorithms with new types (for example, the Bolt \p sort can operate
 * on ints, float, or any custom type defined by the user).
 * Additionally, Bolt lets users customize the template routines using function objects 
 * (functors) written in OpenCL &tm; for example, to provide a custom comparison operation for \p sort, or a custom reduction operation.

 * Bolt can directly interface with host memory structures such as \p std::vector 
 * or host arrays (e.g. \p float*).  On today's GPU systems, the host memory is mapped or copied automatically to the GPU.  
 * On future systems that support the Heterogeneous System Architecture, the GPU will directly access the host data structures. 
 * Bolt also provides a bolt::cl::device_vector that can be used to allocate and manage device-local memory 
 * for higher performance on discrete GPU systems.  Bolt APIs can accept either host memory or the device vector.

 * This document introduces the architecture of Bolt and also provides a reference for the Bolt APIs.  
 * 

 * \section example_sec Examples
 * \subsection simplexample_sec Simple Example
 * The simple example below shows how to use Bolt to sort a random array of 8192 integers.  
 \code
#include <bolt/cl/sort.h>
#include <vector>
#include <algorithm>
 
void main()
{
    // generate random data (on host)
    std::vector<int> a(8192);
    std::generate(a.begin(), a.end(), rand);

    // sort, run on best device in the platform
    bolt::cl::sort(a.begin(), a.end());
}
\endcode

 * The code will be familiar to the programmers who have used the C++ Standard Template Library; the 
 * difference is the include file (bolt/cl/sort.h) and the \p bolt::cl namespace before the \p sort call.  
 * Bolt developers do not need to learn a new device-specific programming model to leverage the power and performance 
 * advantages of GPU computing.
  
 * The example demonstrates two important features of Bolt:
 * \li The host-allocated vector "a" is directly passed to the Bolt \p sort routine, without a need to explicitly allocate and 
 *      manage GPU device memory.
 * \li The Bolt \p bolt::cl::sort call submits to the platform, rather than a specific device.  The Bolt runtime selects
*      the best device to run the sort, potentially running it on the CPU in the event a GPU is not available or the sort 
*      size is too small to benefit from GPU acceleration.


 * \subsection subexample_sec Bolt Functor Example
 * Below example shows how to use Functors with BOLT. 
 * For user defined datatypes to work with BOLT functor, user has to wrap his data type around a macro BOLT_FUNCTOR.
 * This enables the user defined class to be available as a string to the OpenCL Compiler which is invoked during a call to 
 * clBuildProgram(). Consider the following example.    
 \code
BOLT_FUNCTOR(MyType<int>,
template <typename T>
struct MyType {
    T a;

    bool operator() (const MyType& lhs, const MyType& rhs) const  {
        return (lhs.a > rhs.a);
    }
    bool operator < (const MyType& other) const {
        return (a < other.a);
    }
    bool operator > (const MyType& other) const {
        return (a > other.a);
    }
    bool operator >= (const MyType& other) const {
        return (a >= other.a);
    }
    MyType()
        : a(0) { }
};
);
\endcode

After defining the class, user need to register it with BOLT. Internally bolt algorithms will make use of the device_vector class. 
But these are defined only for the basic data types like int, float, unsigned int etc. For User defined data types it’s the 
responsibility of the application developer to create a definition of the deveice_vector for his own defined data type.
See the below example. 
\code
BOLT_TEMPLATE_REGISTER_NEW_TYPE( bolt::cl::greater, int, MyType< int> );
BOLT_TEMPLATE_REGISTER_NEW_ITERATOR( bolt::cl::device_vector, int, MyType< int> );
\endcode
In the above example bolt::cl::greater functor is defined in include/bolt/cl/functional.h. For the user defined data types it is 
the responsibility of the application developer to define as shown above for the functors which he uses from include/bolt/cl/functional.h .

Stitching it all together with a below sample code for Sort:
\code
void main()
{
    typedef MyType<int> mytype;
    std::vector<mytype> myTypeBoltInput(length);
    bolt::cl::sort(myTypeBoltInput.begin(), myTypeBoltInput.end(),bolt::cl::greater<mytype>());
}
\endcode

User can also work with his own defined Functor as shown below:
\code
BOLT_FUNCTOR(uddtD4,
struct uddtD4
{
    double a;
    double b;
    double c;
    double d;
  
};
);
// Functor for UDD. Adds all four double elements and returns true if lhs_sum > rhs_sum
BOLT_FUNCTOR(AddD4,
struct AddD4
{
    bool operator()(const uddtD4 &lhs, const uddtD4 &rhs) const
    {

        if( ( lhs.a + lhs.b + lhs.c + lhs.d ) > ( rhs.a + rhs.b + rhs.c + rhs.d) )
            return true;
        return false;
    };
}; 
);
void main()
{
    std::vector <uddtD4> boltInput(sizeOfInputBuffer);
    bolt::cl::sort( boltInput.begin( ), boltInput.end( ), AddD4() );
}
\endcode

* \subsection subexample2_sec Templatized Bolt Functor 
*  User can also use Templatized version of Bolt Functor with User defined data types as shown below:

\code
BOLT_TEMPLATE_FUNCTOR1( MyFunctor,  int
template <typename T>    
struct MyFunctor{ 
    T a; 
    T b; 
    bool operator() (const MyFunctor& lhs, const MyFunctor& rhs) const { 
        return (lhs.a > rhs.a);
    } 
    bool operator < (const MyFunctor& other) const { 
        return (a < other.a);
    }
    bool operator > (const MyFunctor& other) const { 
        return (a > other.a);
    }
    MyFunctor(const MyFunctor &other) 
        : a(other.a), b(other.b) { } 
    MyFunctor() 
        : a(0), b(0) { } 
    MyFunctor(T& _in) 
        : a(_in), b(_in) { } 
}; 
);

BOLT_TEMPLATE_REGISTER_NEW_TYPE( bolt::cl::greater, int, MyFunctor< int> );
BOLT_TEMPLATE_REGISTER_NEW_ITERATOR( bolt::cl::device_vector, int, MyFunctor< int> );

void main()
{
    typedef MyFunctor<int> myfunctor;
    std::vector <myfunctor> boltInput(sizeOfInputBuffer);
    bolt::cl::sort( boltInput.begin( ), boltInput.end( ), bolt::cl::greater<myfunctor>() );
}
\endcode
If the user wants to use TEMPLATE_FUNCTOR for more than one datatype then he can use other variants of this
like BOLT_TEMPLATE_FUNCTOR2, BOLT_TEMPLATE_FUNCTOR3 etc from include/bolt/cl/clcode.h file.


 * \section Function_Path Supported Functions and Code Paths
 *  List of <a href="supportedFunction.html">Supported Functions and Code Paths</a>.
 * \subsection paths Code Path Behaviour
 * \subsubsection Default Default Behaviour
 * Bolt function is designed to be executed with four code paths (OpenCL™, C++ AMP, Multicore CPU and Serial CPU). The default mode is "Automatic" which means it will go into GPU path first, then TBB (Intel), then SerialCpu 
 * with below mentioned order. The control will go to other paths only if the selected one not found.
 
 * Selection order will be: 
 * \li Run on GPU if AMD GPU is found and AMD APP SDK is installed.
 * \li Run on Multicore CPU if Intel TBB is installed.
 * \li Run CPU serial path.
  
* \subsubsection Force Force Behaviour
* Forcing mode to any device will run the function on that device only. There are two ways in BOLT to force the control to specific Device.
*   -# <b> Setting control to Device Globally: </b>
*      \code bolt::cl::control& myControl = bolt::cl::control::getDefault( );
*  myControl.waitMode( bolt::cl::control::NiceWait );
*  myControl.setForceRunMode( bolt::cl::control::OpenCL );
*      \endcode
*   -# <b> Setting control to Device locally </b>
*       \code bolt::amp::control ctl = bolt::amp::control::getDefault( );
* ctl.setForceRunMode(bolt::amp::control::OpenCL);
*       \endcode
* This will set the control to specified device locally, passing this control object to BOLT function enables specified device 
* path only for that function, so reference to any BOLT function will always run specified device path.


 * \section Requirements Requirements 
 * Bolt uses an OpenCL<SUP>TM</SUP> implementation that supports the static C++ kernel
 * features; specifically, C++ template support for OpenCL<SUP>TM</SUP> kernels.  Currently,
 * the AMD OpenCL<SUP>TM</SUP> SDK 2.7 and above versions are designed to provides this support; other vendors may adopt this feature in the future. 
 * If you face any issue with Bolt. Please log an issue in BOLT Issues page.
 * <a href="https://github.com/HSA-Libraries/bolt/issues">BOLT Issues page</a>.
 */
